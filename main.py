"""
Smart Inventory Management System - Main Pipeline
This script orchestrates the entire inventory management workflow including
data preprocessing, expiry prediction, and comprehensive analysis.
"""

import os
import sys
import logging
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import pandas as pd

# Setup project paths - use pathlib for better cross-platform compatibility
PROJECT_ROOT = Path(__file__).parent.absolute()
SRC_PATH = PROJECT_ROOT / 'src'

# Add paths to Python path for module imports
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(SRC_PATH))

def setup_logging() -> logging.Logger:
    """Configure logging with proper error handling"""
    log_dir = PROJECT_ROOT / "logs"
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / "main_pipeline.log"
    
    # Configure logging format
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8", mode='a'),
            logging.StreamHandler(sys.stdout)
        ],
        force=True  # Override any existing logging config
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"Logging initialized. Log file: {log_file}")
    return logger

# Initialize logger
logger = setup_logging()

def import_modules() -> Tuple[Any, Any, Optional[Any], Optional[Any], Optional[Any]]:
    """
    Import required modules with proper fallback handling
    Returns: (train_expiry_model, inventory_analyzer, data_preprocessing, transform_inventory_data, utils)
    """
    train_expiry_model = None
    inventory_analyzer = None
    data_preprocessing = None
    transform_inventory_data = None
    utils = None
    
    try:
        from src import train_expiry_model, inventory_analyzer, data_preprocessing
        logger.info("‚úÖ Successfully imported core modules from src package")
    except ImportError as e:
        logger.error(f"‚ùå Failed to import core modules: {e}")
        logger.error("Required files:")
        logger.error(f"  - {SRC_PATH / 'train_expiry_model.py'}")
        logger.error(f"  - {SRC_PATH / 'inventory_analyzer.py'}")
        logger.error(f"  - {SRC_PATH / 'data_preprocessing.py'}")
        raise ImportError("Cannot proceed without required modules") from e
    
    # Import donation-related modules
    try:
        from src import utils
        logger.info("‚úÖ Successfully imported utils module")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Failed to import utils module: {e}")
        utils = None
    
    try:
        import transform_inventory_data
        logger.info("‚úÖ Successfully imported transform_inventory_data module")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Failed to import transform_inventory_data module: {e}")
        transform_inventory_data = None
    
    return train_expiry_model, inventory_analyzer, data_preprocessing, transform_inventory_data, utils

def ensure_directories() -> bool:
    """Create required directories with proper error handling"""
    required_dirs = [
        PROJECT_ROOT / "logs",
        PROJECT_ROOT / "models",
        PROJECT_ROOT / "data" / "processed",
        PROJECT_ROOT / "data" / "raw",
        PROJECT_ROOT / "plots",
        PROJECT_ROOT / "dashboard" / "cache"
    ]
    
    logger.info("üîß Ensuring required directories exist...")
    
    for directory in required_dirs:
        try:
            directory.mkdir(parents=True, exist_ok=True)
            logger.debug(f"‚úÖ Directory ready: {directory}")
        except PermissionError:
            logger.error(f"‚ùå Permission denied creating: {directory}")
            return False
        except Exception as e:
            logger.error(f"‚ùå Failed to create directory {directory}: {e}")
            return False
    
    logger.info("‚úÖ All required directories verified")
    return True

def check_data_files() -> bool:
    """Check if required data files exist"""
    data_file_locations = [
        PROJECT_ROOT / "data" / "processed" / "inventory_data.csv",
        PROJECT_ROOT / "data" / "raw" / "inventory_data.csv"
    ]
    
    for data_file in data_file_locations:
        if data_file.exists():
            logger.info(f"‚úÖ Found data file: {data_file}")
            return True
    
    logger.warning("‚ö†Ô∏è No data files found in expected locations:")
    for location in data_file_locations:
        logger.warning(f"  - {location}")
    
    return False

def run_data_preprocessing(data_preprocessing_module) -> bool:
    """Run data preprocessing if needed and available"""
    try:
        if check_data_files():
            logger.info("‚úÖ Data files already exist, skipping preprocessing")
            return True
        
        logger.info("üîÑ Running data preprocessing...")
        
        if hasattr(data_preprocessing_module, 'preprocess_data'):
            data_preprocessing_module.preprocess_data()
        else:
            logger.error("‚ùå data_preprocessing module missing 'preprocess_data()' function")
            return False
        
        if check_data_files():
            logger.info("‚úÖ Data preprocessing completed successfully")
            return True
        else:
            logger.error("‚ùå Data preprocessing completed but no output files found")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error in data preprocessing: {e}")
        logger.exception("Preprocessing error details:")
        return False

def run_expiry_prediction(train_expiry_model) -> bool:
    """Run the expiry risk prediction model"""
    try:
        logger.info("üîç Phase 1: Running expiry risk prediction model...")
        
        if hasattr(train_expiry_model, 'train_and_predict'):
            train_expiry_model.train_and_predict()
            logger.info("‚úÖ Expiry risk prediction completed")
            return True
        else:
            logger.error("‚ùå train_expiry_model module missing 'train_and_predict()' function")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Error in expiry risk prediction: {e}")
        logger.exception("Expiry prediction error details:")
        return False

def run_inventory_analysis(inventory_analyzer) -> Tuple[bool, Optional[pd.DataFrame], Optional[Dict]]:
    """Run comprehensive inventory analysis"""
    try:
        logger.info("üìä Phase 2: Running comprehensive inventory analysis...")
        
        if hasattr(inventory_analyzer, 'InventoryAnalyzer'):
            analyzer = inventory_analyzer.InventoryAnalyzer(str(PROJECT_ROOT))
            df, summary = analyzer.run_full_analysis()
            
            logger.info("‚úÖ Inventory analysis completed")
            return True, df, summary
        else:
            logger.error("‚ùå inventory_analyzer module missing 'InventoryAnalyzer' class")
            return False, None, None
        
    except Exception as e:
        logger.error(f"‚ùå Error in inventory analysis: {e}")
        logger.exception("Inventory analysis error details:")
        return False, None, None

def save_dashboard_data(df: pd.DataFrame) -> bool:
    """Save data for dashboard consumption"""
    try:
        logger.info("üìà Phase 3: Preparing dashboard data...")
        
        dashboard_cache_dir = PROJECT_ROOT / "dashboard" / "cache"
        dashboard_cache_dir.mkdir(parents=True, exist_ok=True)
        
        dashboard_data_path = dashboard_cache_dir / "dashboard_data.csv"
        df.to_csv(dashboard_data_path, index=False)
        
        logger.info(f"‚úÖ Dashboard data saved: {dashboard_data_path}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error saving dashboard data: {e}")
        logger.exception("Dashboard data save error:")
        return False

def safe_get_summary_value(summary: Dict[str, Any], key: str, default: Any = "N/A") -> str:
    """Safely extract and format summary values"""
    try:
        value = summary.get(key, default)
        if key in ['total_inventory_value'] and isinstance(value, (int, float)):
            return f"${value:,.2f}"
        elif key in ['total_items'] and isinstance(value, (int, float)):
            return f"{value:,}"
        else:
            return str(value)
    except Exception:
        return str(default)

def display_summary(summary: Dict[str, Any]) -> None:
    """Display analysis summary with safe error handling"""
    try:
        logger.info("üìä Analysis Summary:")
        logger.info(f"   üì¶ Total Items: {safe_get_summary_value(summary, 'total_items')}")
        logger.info(f"   üí∞ Total Value: {safe_get_summary_value(summary, 'total_inventory_value')}")
        
        actions_needed = summary.get('actions_needed', {})
        if isinstance(actions_needed, dict):
            high_risk = actions_needed.get('Remove', 0) + actions_needed.get('Apply Discount', 0)
            logger.info(f"   ‚ö†Ô∏è  High Risk Items: {high_risk}")
        else:
            logger.info("   ‚ö†Ô∏è  High Risk Items: N/A")
        
        logger.info(f"   üì¶ Reorder Needed: {safe_get_summary_value(summary, 'items_needing_reorder')}")
        
    except Exception as e:
        logger.warning(f"Could not display complete summary: {e}")
        logger.info("   üìä Summary data available but formatting incomplete")

def run_donation_data_processing(transform_inventory_data) -> Tuple[bool, Optional[pd.DataFrame]]:
    """Run donation data processing and transformation"""
    try:
        logger.info("ü§ù PROCESSING DONATION DATA...")
        logger.info("‚ïê" * 50)
        
        if transform_inventory_data is None:
            logger.warning("‚ö†Ô∏è transform_inventory_data module not available, skipping donation processing")
            return False, None
        
        if hasattr(transform_inventory_data, 'load_and_transform_data'):
            # Load and transform data with donation logic
            df = transform_inventory_data.load_and_transform_data()
            
            if df is not None and len(df) > 0:
                logger.info(f"‚úÖ Donation data processing completed: {len(df):,} rows")
                
                # Quick preview of the new Action logic results
                if 'Action' in df.columns:
                    action_counts = df['Action'].value_counts()
                    logger.info("‚ö° ACTION DISTRIBUTION PREVIEW:")
                    for action, count in action_counts.items():
                        if action == 'Remove':
                            logger.info(f"   üóëÔ∏è  {action}: {count:,}")
                        elif action == 'Donate':
                            logger.info(f"   ü§ù {action}: {count:,}")
                        elif action == 'Apply Discount':
                            logger.info(f"   üí∏ {action}: {count:,}")
                        elif action == 'Restock':
                            logger.info(f"   üì¶ {action}: {count:,}")
                        else:
                            logger.info(f"   ‚úÖ {action}: {count:,}")
                
                return True, df
            else:
                logger.error("‚ùå Donation data processing returned empty or None DataFrame")
                return False, None
        else:
            logger.error("‚ùå transform_inventory_data module missing 'load_and_transform_data()' function")
            return False, None
        
    except Exception as e:
        logger.error(f"‚ùå Error in donation data processing: {e}")
        logger.exception("Donation processing error details:")
        return False, None

def analyze_donation_data(df: pd.DataFrame, utils_module=None) -> None:
    """Analyze and log donation data statistics with enhanced validation and metrics"""
    try:
        logger.info("üìä ANALYZING DONATION DATA...")
        logger.info("‚ïê" * 60)
        
        # Validate donation data first
        is_valid, validation_message = validate_donation_data(df)
        if not is_valid:
            logger.error(f"‚ùå Donation data validation failed: {validation_message}")
            return
        
        # Display comprehensive donation metrics
        display_donation_metrics(df)
        
        # Top 5 cities with most donations (ACTUAL DONATED ITEMS)
        if 'city' in df.columns and 'donation_status' in df.columns:
            donated_items = df[df['donation_status'] == 'Donated']
            if len(donated_items) > 0:
                top_cities = donated_items['city'].value_counts().head(5)
                logger.info("üèôÔ∏è TOP 5 CITIES WITH MOST DONATIONS (Actual Donated):")
                logger.info("‚îÄ" * 50)
                for i, (city, count) in enumerate(top_cities.items(), 1):
                    logger.info(f"   {i}. {city:15}: {count:4} donations")
            else:
                logger.info("üèôÔ∏è No donated items found for city analysis")
        
        # Top 5 NGOs by donation count (ACTUAL DONATED ITEMS)
        if 'nearest_ngo' in df.columns and 'donation_status' in df.columns:
            donated_items = df[df['donation_status'] == 'Donated']
            if len(donated_items) > 0:
                top_ngos = donated_items['nearest_ngo'].value_counts().head(5)
                logger.info("üè¢ TOP 5 NGOs BY ACTUAL DONATIONS:")
                logger.info("‚îÄ" * 50)
                for i, (ngo, count) in enumerate(top_ngos.items(), 1):
                    ngo_name = str(ngo)[:30] if len(str(ngo)) > 30 else str(ngo)
                    logger.info(f"   {i}. {ngo_name:30}: {count:4} donations")
            else:
                logger.info("üè¢ No donated items found for NGO analysis")
        
        # Expiry-based action analysis
        if 'days_to_expiry' in df.columns and 'Action' in df.columns:
            logger.info("üìÖ EXPIRY-BASED ACTION ANALYSIS:")
            logger.info("‚îÄ" * 50)
            
            # Items to remove (too expired)
            remove_items = df[df['Action'] == 'Remove']
            logger.info(f"üóëÔ∏è  Items to Remove (too expired):     {len(remove_items):,}")
            
            # Items for donation
            donate_items = df[df['Action'] == 'Donate']
            logger.info(f"ü§ù Items for Donation:               {len(donate_items):,}")
            
            # Items for discount
            discount_items = df[df['Action'] == 'Apply Discount']
            logger.info(f"üí∏ Items for Discount:               {len(discount_items):,}")
            
            # Calculate potential value loss from removed items
            if 'unit_price' in df.columns and 'current_stock' in df.columns:
                removed_value = (remove_items['unit_price'] * remove_items['current_stock']).sum()
                donated_value = (donate_items['unit_price'] * donate_items['current_stock']).sum()
                discount_value = (discount_items['unit_price'] * discount_items['current_stock']).sum()
                
                logger.info(f"üí∞ Value Analysis:")
                logger.info(f"   üí∏ Potential Loss (Remove):        ${removed_value:,.2f}")
                logger.info(f"   ü§ù Value Recovered (Donate):       ${donated_value:,.2f}")
                logger.info(f"   üè∑Ô∏è  Discount Opportunity:           ${discount_value:,.2f}")
        
        # Use utils module for comprehensive summary if available
        if utils_module and hasattr(utils_module, 'get_donation_summary'):
            try:
                donation_summary = utils_module.get_donation_summary(df)
                logger.info("üìä COMPREHENSIVE DONATION SUMMARY (from utils):")
                logger.info("‚îÄ" * 50)
                
                # Extract key metrics from utils summary
                eligible_pct = donation_summary.get('donation_eligible_percentage', 0)
                if eligible_pct > 0:
                    logger.info(f"   ‚úÖ Donation eligible percentage: {eligible_pct:.1f}%")
                
                status_counts = donation_summary.get('donation_status_counts', {})
                if status_counts:
                    logger.info(f"   üìã Status distribution: {dict(status_counts)}")
                
                top_ngos_from_summary = donation_summary.get('top_ngos', {})
                if top_ngos_from_summary:
                    logger.info("üèÜ Top NGOs from comprehensive analysis:")
                    for ngo, count in list(top_ngos_from_summary.items())[:3]:
                        logger.info(f"   ‚Ä¢ {ngo}: {count} items")
                        
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not generate comprehensive donation summary: {e}")
        
        logger.info("‚úÖ DONATION DATA ANALYSIS COMPLETED SUCCESSFULLY")
        logger.info("‚ïê" * 60)
        
    except Exception as e:
        logger.error(f"‚ùå Error analyzing donation data: {e}")
        logger.exception("Donation analysis error details:")

def save_enhanced_dataset(df: pd.DataFrame, utils_module=None) -> bool:
    """Save the enhanced dataset with donation data and separate output files"""
    try:
        logger.info("üíæ SAVING ENHANCED DATASETS...")
        logger.info("‚ïê" * 50)
        
        # Save main enhanced dataset
        output_path = PROJECT_ROOT / "data" / "processed" / "inventory_analysis_results_enhanced.csv"
        
        if utils_module and hasattr(utils_module, 'save_updated_inventory'):
            success = utils_module.save_updated_inventory(df, str(output_path))
            if not success:
                logger.warning("‚ö†Ô∏è Utils save failed, falling back to direct pandas save")
                output_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_csv(output_path, index=False)
        else:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            df.to_csv(output_path, index=False)
        
        logger.info(f"‚úÖ Enhanced dataset saved: {output_path}")
        logger.info(f"   üìä Total rows: {len(df):,}")
        
        # Save removed items separately (Action == "Remove")
        if 'Action' in df.columns:
            removed_items_df = df[df['Action'] == 'Remove']
            if len(removed_items_df) > 0:
                removed_items_path = PROJECT_ROOT / "data" / "processed" / "removed_items.csv"
                removed_items_df.to_csv(removed_items_path, index=False)
                logger.info(f"üóëÔ∏è  Removed items saved: {removed_items_path}")
                logger.info(f"   üìä Items to remove: {len(removed_items_df):,}")
                
                # Calculate total value of removed items
                if 'unit_price' in removed_items_df.columns and 'current_stock' in removed_items_df.columns:
                    total_removed_value = (removed_items_df['unit_price'] * removed_items_df['current_stock']).sum()
                    logger.info(f"   üí∞ Total value loss: ${total_removed_value:,.2f}")
            else:
                logger.info("‚úÖ No items marked for removal found")
        
        # Save donation summary CSV (only donation-eligible items)
        if 'donation_eligible' in df.columns:
            donation_eligible_df = df[df['donation_eligible'] == True]
            if len(donation_eligible_df) > 0:
                donation_summary_path = PROJECT_ROOT / "data" / "processed" / "donation_summary.csv"
                donation_eligible_df.to_csv(donation_summary_path, index=False)
                logger.info(f"ü§ù Donation summary saved: {donation_summary_path}")
                logger.info(f"   üìä Donation eligible items: {len(donation_eligible_df):,}")
                
                # Break down by donation status
                if 'donation_status' in donation_eligible_df.columns:
                    status_breakdown = donation_eligible_df['donation_status'].value_counts()
                    for status, count in status_breakdown.items():
                        if status == 'Pending':
                            logger.info(f"   üü° Pending: {count:,}")
                        elif status == 'Donated':
                            logger.info(f"   üü¢ Donated: {count:,}")
                        elif status == 'Rejected':
                            logger.info(f"   üî¥ Rejected: {count:,}")
                        else:
                            logger.info(f"   ‚ö™ {status}: {count:,}")
            else:
                logger.info("‚ÑπÔ∏è No donation-eligible items found, skipping donation summary CSV")
        else:
            logger.warning("‚ö†Ô∏è No donation_eligible column found, skipping donation summary CSV")
        
        # Save pending donations for NGO coordination
        if 'donation_status' in df.columns and 'donation_eligible' in df.columns:
            pending_donations_df = df[(df['donation_eligible'] == True) & (df['donation_status'] == 'Pending')]
            if len(pending_donations_df) > 0:
                pending_donations_path = PROJECT_ROOT / "data" / "processed" / "pending_donations.csv"
                
                # Include key columns for NGO coordination
                key_columns = ['item_id', 'product_name', 'category', 'current_stock', 'days_to_expiry', 
                              'city', 'nearest_ngo', 'ngo_contact', 'ngo_address', 'donation_status']
                available_columns = [col for col in key_columns if col in pending_donations_df.columns]
                
                pending_donations_df[available_columns].to_csv(pending_donations_path, index=False)
                logger.info(f"üü° Pending donations saved: {pending_donations_path}")
                logger.info(f"   üìä Pending items: {len(pending_donations_df):,}")
                
                # Top NGOs for pending donations
                if 'nearest_ngo' in pending_donations_df.columns:
                    top_ngos_pending = pending_donations_df['nearest_ngo'].value_counts().head(3)
                    logger.info("   üè¢ Top NGOs for pending donations:")
                    for i, (ngo, count) in enumerate(top_ngos_pending.items(), 1):
                        ngo_name = str(ngo)[:25] if len(str(ngo)) > 25 else str(ngo)
                        logger.info(f"      {i}. {ngo_name}: {count} items")
        
        logger.info("‚úÖ ALL DATASETS SAVED SUCCESSFULLY")
        logger.info("‚ïê" * 50)
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error saving enhanced dataset: {e}")
        logger.exception("Enhanced dataset save error:")
        return False

def validate_donation_data(df: pd.DataFrame) -> Tuple[bool, str]:
    """
    Validate donation data integrity and completeness
    Returns: (is_valid, error_message)
    """
    try:
        # Check required columns exist
        required_columns = ['donation_eligible', 'donation_status']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            return False, f"Missing required donation columns: {missing_columns}"
        
        # Check data types
        if df['donation_eligible'].dtype != bool:
            # Try to convert if it's 0/1 or True/False strings
            try:
                df['donation_eligible'] = df['donation_eligible'].astype(bool)
            except:
                return False, "donation_eligible column is not boolean and cannot be converted"
        
        # Check donation status values
        valid_statuses = ['', 'Pending', 'Donated', 'Cancelled']
        invalid_statuses = df[~df['donation_status'].isin(valid_statuses)]['donation_status'].unique()
        
        if len(invalid_statuses) > 0:
            logger.warning(f"‚ö†Ô∏è Found unexpected donation statuses: {list(invalid_statuses)}")
        
        # Check for logical consistency
        eligible_count = df['donation_eligible'].sum()
        pending_donated_count = df[df['donation_status'].isin(['Pending', 'Donated'])].shape[0]
        
        if pending_donated_count > eligible_count:
            logger.warning("‚ö†Ô∏è More items with Pending/Donated status than eligible items")
        
        # Check NGO data completeness for donated items
        if 'nearest_ngo' in df.columns:
            donated_items = df[df['donation_status'] == 'Donated']
            missing_ngo_data = donated_items['nearest_ngo'].isna().sum()
            
            if missing_ngo_data > 0:
                logger.warning(f"‚ö†Ô∏è {missing_ngo_data} donated items missing NGO information")
        
        logger.info("‚úÖ Donation data validation passed")
        return True, "Validation successful"
        
    except Exception as e:
        return False, f"Validation error: {e}"

def display_donation_metrics(df: pd.DataFrame) -> None:
    """Display comprehensive donation metrics in a formatted way"""
    try:
        logger.info("ü§ù DONATION METRICS DASHBOARD")
        logger.info("‚ïê" * 60)
        
        total_items = len(df)
        
        if 'donation_eligible' in df.columns:
            eligible_items = df['donation_eligible'].sum()
            eligible_percentage = (eligible_items / total_items * 100) if total_items > 0 else 0
            logger.info(f"üì¶ Total Items:              {total_items:,}")
            logger.info(f"ü§ù Donation Eligible:        {eligible_items:,} ({eligible_percentage:.1f}%)")
        
        if 'donation_status' in df.columns:
            status_counts = df['donation_status'].value_counts()
            logger.info("üìã DONATION STATUS BREAKDOWN:")
            logger.info("‚îÄ" * 30)
            
            for status in ['Pending', 'Donated', 'Rejected', 'Cancelled']:
                count = status_counts.get(status, 0)
                percentage = (count / total_items * 100) if total_items > 0 else 0
                if status == 'Pending':
                    logger.info(f"   üü° {status:10}: {count:6,} ({percentage:4.1f}%)")
                elif status == 'Donated':
                    logger.info(f"   üü¢ {status:10}: {count:6,} ({percentage:4.1f}%)")
                elif status == 'Rejected':
                    logger.info(f"   üî¥ {status:10}: {count:6,} ({percentage:4.1f}%)")
                else:
                    logger.info(f"   ‚ö™ {status:10}: {count:6,} ({percentage:4.1f}%)")
        
        # Action analysis
        if 'Action' in df.columns:
            action_counts = df['Action'].value_counts()
            logger.info("‚ö° ACTION BREAKDOWN:")
            logger.info("‚îÄ" * 30)
            
            action_emojis = {
                'Remove': 'üóëÔ∏è',
                'Donate': 'ü§ù',
                'Apply Discount': 'üí∏',
                'Restock': 'üì¶',
                'No Action': '‚úÖ'
            }
            
            for action in ['Remove', 'Donate', 'Apply Discount', 'Restock', 'No Action']:
                count = action_counts.get(action, 0)
                percentage = (count / total_items * 100) if total_items > 0 else 0
                emoji = action_emojis.get(action, 'üìã')
                logger.info(f"   {emoji} {action:15}: {count:6,} ({percentage:4.1f}%)")
        
        # Category analysis for donations
        if 'category' in df.columns and 'donation_eligible' in df.columns:
            eligible_by_category = df[df['donation_eligible']]['category'].value_counts().head(5)
            if len(eligible_by_category) > 0:
                logger.info("üè∑Ô∏è TOP 5 CATEGORIES (Donation Eligible):")
                logger.info("‚îÄ" * 30)
                for i, (category, count) in enumerate(eligible_by_category.items(), 1):
                    logger.info(f"   {i}. {category}: {count:,} items")
        
        # Geographic distribution
        if 'city' in df.columns and 'donation_eligible' in df.columns:
            eligible_by_city = df[df['donation_eligible']]['city'].value_counts().head(5)
            if len(eligible_by_city) > 0:
                logger.info("üèôÔ∏è TOP 5 CITIES (Donation Eligible):")
                logger.info("‚îÄ" * 30)
                for i, (city, count) in enumerate(eligible_by_city.items(), 1):
                    logger.info(f"   {i}. {city}: {count:,} items")
        
        logger.info("‚ïê" * 60)
        
    except Exception as e:
        logger.error(f"‚ùå Error displaying donation metrics: {e}")

def main() -> bool:
    """Main pipeline execution function"""
    logger.info("üöÄ Starting Smart Inventory Management Pipeline")
    logger.info("=" * 60)
    
    try:
        # Import required modules
        train_expiry_model, inventory_analyzer, data_preprocessing, transform_inventory_data, utils = import_modules()
        
        # Ensure directory structure
        if not ensure_directories():
            logger.error("‚ùå Failed to create required directories")
            return False
        
        # Phase 0: Data Preprocessing
        logger.info("üîß Phase 0: Ensuring data is prepared...")
        if not run_data_preprocessing(data_preprocessing):
            logger.error("‚ùå Data preprocessing failed")
            return False
        
        # Phase 1: Expiry Risk Prediction
        if not run_expiry_prediction(train_expiry_model):
            return False
        
        # Phase 2: Inventory Analysis
        success, df, summary = run_inventory_analysis(inventory_analyzer)
        if not success:
            return False
        
        # Phase 3: Dashboard Data
        if df is not None:
            if not save_dashboard_data(df):
                logger.warning("‚ö†Ô∏è Dashboard data save failed, but continuing...")
        
        # Phase 3.5: Donation Data Processing and Analysis
        logger.info("ü§ù PHASE 3.5: PROCESSING AND ANALYZING DONATION DATA...")
        logger.info("‚ïê" * 70)
        donation_success, donation_df = run_donation_data_processing(transform_inventory_data)
        if donation_success and donation_df is not None:
            # Validate donation data
            is_valid, validation_message = validate_donation_data(donation_df)
            if not is_valid:
                logger.error(f"‚ùå Donation data validation failed: {validation_message}")
                return False
            
            analyze_donation_data(donation_df, utils)
            
            # Save enhanced dataset with donation data
            if save_enhanced_dataset(donation_df, utils):
                logger.info("‚úÖ Enhanced dataset with donation data saved successfully")
            else:
                logger.warning("‚ö†Ô∏è Failed to save enhanced dataset")
                
            # Log final donation integration summary
            eligible_count = donation_df['donation_eligible'].sum() if 'donation_eligible' in donation_df.columns else 0
            pending_count = len(donation_df[donation_df['donation_status'] == 'Pending']) if 'donation_status' in donation_df.columns else 0
            donated_count = len(donation_df[donation_df['donation_status'] == 'Donated']) if 'donation_status' in donation_df.columns else 0
            removed_count = len(donation_df[donation_df['Action'] == 'Remove']) if 'Action' in donation_df.columns else 0
            
            logger.info("üéØ FINAL DONATION INTEGRATION SUMMARY:")
            logger.info("‚ïê" * 50)
            logger.info(f"   üìä Total items processed:       {len(donation_df):,}")
            logger.info(f"   ü§ù Donation eligible items:     {eligible_count:,}")
            logger.info(f"   üü° Pending donations:           {pending_count:,}")
            logger.info(f"   üü¢ Successfully donated:        {donated_count:,}")
            logger.info(f"   üóëÔ∏è  Items marked for removal:    {removed_count:,}")
            logger.info(f"   üíæ Enhanced dataset saved to:   data/processed/")
            logger.info("‚ïê" * 50)
        else:
            logger.warning("‚ö†Ô∏è Donation data processing failed, continuing without donation features")
            logger.warning("   This may be due to missing donation modules or data files")
        
        # Display results
        logger.info("üéØ ALL PHASES EXECUTED SUCCESSFULLY!")
        logger.info("‚ïê" * 70)
        if summary:
            display_summary(summary)
        
        # Final output summary
        logger.info("üìã OUTPUT FILES GENERATED:")
        logger.info("‚îÄ" * 40)
        logger.info("   üìÑ inventory_analysis_results_enhanced.csv")
        logger.info("   üìÑ donation_summary.csv (donation eligible items)")
        logger.info("   üìÑ removed_items.csv (items marked for removal)")
        logger.info("   üìÑ pending_donations.csv (items pending donation)")
        logger.info("   üìÑ dashboard_data.csv (for dashboard)")
        
        logger.info("üåê NEXT STEPS:")
        logger.info("‚îÄ" * 40)
        logger.info("   1. Run dashboard: streamlit run dashboard/app.py")
        logger.info("   2. Review removed items for disposal")
        logger.info("   3. Coordinate with NGOs for pending donations")
        logger.info("   4. Apply discounts to near-expiry items")
        logger.info("‚ïê" * 70)
        
        return True
        
    except KeyboardInterrupt:
        logger.info("‚ö†Ô∏è Pipeline interrupted by user")
        return False
    except Exception as e:
        logger.error(f"‚ùå Unexpected pipeline error: {e}")
        logger.exception("Pipeline error details:")
        return False

if __name__ == "__main__":
    try:
        success = main()
        exit_code = 0 if success else 1
        
        if success:
            logger.info("üéâ Pipeline execution completed successfully!")
        else:
            logger.error("‚ùå Pipeline execution failed")
        
        sys.exit(exit_code)
        
    except Exception as e:
        logger.error(f"‚ùå Critical error: {e}")
        logger.exception("Critical error details:")
        sys.exit(1)